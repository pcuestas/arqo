\documentclass{article}

\usepackage[margin=2.5cm]{geometry}

\usepackage[utf8]{inputenc}


\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{fancyvrb}

\usepackage{tcolorbox}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{.2,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{codeblue}{rgb}{0,0.4,0.82}
\definecolor{codeorange}{rgb}{0.94,0.34,0.0}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{backcolourgray}{rgb}{0.92,0.92,0.92}
\definecolor{codewhite}{rgb}{1,1,1}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolourgray},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{codeblue},
    numberstyle=\tiny\color{black},
    stringstyle=\color{codeorange},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    %numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    extendedchars=true,
    frame=single
    %, basicstyle=\footnotesize
}
\lstset{style=mystyle}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

\pagestyle{fancy}
\fancyhf{}
\rhead{Arquitectura de ordenadores. Practice 3.}
\lhead{Pablo Cuesta Sierra, Álvaro Zamanillo Sáez}
\cfoot{\thepage}



%\setlength{\parskip}{0.15cm}


%parameters: file, caption, label, scale
\newcommand{\myFigure}[4]{%
    \begin{figure}[!ht]
        \includegraphics[scale=#4]{#1}
        \centering
        \caption{#2}
        \label{#3}
    \end{figure}
}


\begin{document}


\title{Arquitectura de ordenadores. Practice 3.}
\author{Pablo Cuesta Sierra, Álvaro Zamanillo Sáez}
%\date{}
\maketitle

%\begin{tcolorbox}
%\tableofcontents
%\end{tcolorbox}

\addcontentsline{toc}{subsection}{Exercise 0}
\subsection*{Exercise 0}

We have been submitting our tasks to the \emph{MV} queue for all exercises of the practice because it returned the best (smoothest) results. 

After running the commands shown in the statement, we got these results. 

As can be seen in figure \ref{cache_conf}, the first level is the only one where there are two different caches: one for data and another for instructions. Both are of the same kind: size of 32768 B (32 KB), with blocks of 64 B and 8 ways. 
In the second level, there is a unique cache which is larger (2097152 B = 2 MB) but has the same degree of associativity. For the third level, the size increases (16777216 B = 16 MB) as well as the associativity (16 ways) whereas the block size remains the same.

\begin{figure}[h]
    \lstinputlisting[]{../material_P3/out0/mv/cache.dat}
    \centering
    \caption{Output of \texttt{getconf -a | grep -i cache}}
    \label{cache_conf}
\end{figure}

\pagebreak

Here is the info of the each of the processors (this is processor 0, but they are all the same):

\begin{figure}[h]
    \lstinputlisting[firstline=0,lastline=18]{../material_P3/out0/mv/cpuinfo.dat}
    \centering
    \caption{First lines of \texttt{/proc/cpuinfo}}
    \label{cpuinfo}
\end{figure}

The following diagram shows the archiquetecture of the different caches in each of the 8 cores. 

\myFigure{../material_P3/out0/mv/figure.png}{Topology of the used CPU.}{topology}{0.34}

\pagebreak

\addcontentsline{toc}{subsection}{Exercise 1}
\subsection*{Exercise 1}

The following image shows a graph with the execution time of both programs for different sizes of the matrix.

\myFigure{../material_P3/out1/mv_att4/slow_fast_time.png}{Slow vs Fast execution times.}{slow_fast_times}{0.65}

As pointed by the graph, the execution time for small values of N is similar for both programs (most of the matrix can be stored completely in the cache). However, as N grows, the execution time for the slow program shows a significant cuadratic behaviour while the fast version barely grows.

This is due to the fact that the matrix is stored by rows in main memory, and therefore stored in the cache by rows too. The slow version access the matrix by columns which leads to a higher number of misses and consequently, a higer number of accesses to main memory (hundreds of times slower). 

For obtaining the results, it is necessary to run the simulation several times in order to calculate a mean and have more than one result, so that the programs do not present abnormal outliers because of other factors different from what we are measuring. Furthermore, the chosen execution pattern alternates between the slow and fast version to prevent the programs from reusing the cache from the previous execution (with the same size).

\pagebreak

\addcontentsline{toc}{subsection}{Exercise 2}
\subsection*{Exercise 2}

First, we will analyze the write misses: 

\myFigure{../material_P3/out2/mv_att1/cache_escritura.png}{Cache write misses.}{cache_escritura}{0.55}


It may seem that only four lines have been plotted, however this is not the case. (We have plotted the slow graphs with a bit of transparency so that the fast graphs can also be seen). The slow and fast version have (almost) the same number of write misses (for the same execution values of N and size of the cache). The reason behind this is that both programs fill (write) the initial matrix in the same way, by rows (\texttt{generateMatrix(int size)}).

On the other hand, the read misses show different results:

\myFigure{../material_P3/out2/mv_att1/cache_lectura.png}{Cache read misses.}{cache_lectura}{0.55}

This time, we get 8 different lines, as one could expected beforehand. The dotted lines show the fast version, which necessarily must have less read misses than the fast one (when compared with the same cache size). Again, this is due to the fact that the matrix is stored by rows (one row beside the next, sequentially), and the slow version accesses by columns, while the fast version accesses by rows.

The effect of the cache size can also be observed as the fast version for the smallest cache produces more misses than the slow version of the two largest caches. In general, it is to be expected that smaller sized caches would provoke a higher number of misses for the same program; which is what we see in figure \ref{cache_lectura}.



\addcontentsline{toc}{subsection}{Exercise 3}
\subsection*{Exercise 3}

The image below (figure \ref{mult_time}) shows the execution time for the two different multiplication methods. The transposed multiplication is significantly faster as it accesses matrixes by rows when multiplying. On the other hand, in the regular multiplication, the second operand matrix is accessed by columns which produces a high rate of read misses and as a result a higher execution time.

Commenting on the strange peaks that appear in figure \ref{mult_time}, we do not know the real reason why this happens. These peaks are neither because of some mistake on calculating values, nor inconsistencies in execution that could be solved repeating the tests. The values of over 10 seconds when executing for size $N=1408$ are pretty consistant when executing in queue \emph{mv.q} of the cluster (the same goes for the rest of the matrix sizes); meaning that the time in each iteration does not vary more than $0.1s$ for each $N$. If we execute the same script in another queue (\emph{amd.q}, for instance), peaks still appear, but not necessarily in the same sizes ($N$). We think this strange and counterintuitive beahviour might be caused by inefficient use of caches, and that certain sizes of matrixes are managed more efficiently by the cache (because its size is a multiple of the block size, for example) than others; even if this other ones are smaller.

\myFigure{../material_P3/out3/mv_att2/mult_time.png}{Multiplication execution time}{mult_time}{0.65}

When simulating with \emph{valgrind} (figure \ref{mult_misses}), we get very similar results to what we saw in exercise 2 (figure \ref{cache_lectura}). The less optimized program (regular multiplication), which reads matrix $\mathbf{B}$ by columns (instead of by rows), produces a higher number of read misses than the ``transposed multiplication'', which accesses matrix $\mathbf{B}^T$ by rows.

The regular matrix multiplication shows a step pattern every two times we increase the value of N. This may be due to alignment of the data as we are increasing the matrix by 32 and the block size of the cache is 64B. 

\myFigure{../material_P3/out3/mv_att2/mult_cache.png}{Cache misses of the multiplication programs}{mult_misses}{0.6}

The write misses cannot be appreciated in figure \ref{mult_misses}, as they are much lower in value than the read misses, so we have plotted them in a separate graph (figure \ref{mult_misses_write}). Like in exercise 2, both programs write in the same manner: when generating matrixes $\mathbf{A}$ and $\mathbf{B}$, and when writing the result in matrix $\mathbf{C}=\mathbf{AB}$. So, as expected, the write misses are very similar. If we look closely at the exact numbers, we can see that the number of write misses is a bit higher (by less than $10$ units) in the transposed version (for all sizes of the matrixes). This is completely normal, bacause the transposed multiplication has to (re)write most of the values of matrix $\mathbf{B}$ when transposing it before multiplying; this is what causes the (insignificant) extra write misses in this program, which do not appear in the other one. 

\myFigure{../material_P3/out3/mv_att2/mult_cache_write.png}{Cache write misses of the multiplication programs}{mult_misses_write}{0.4}


\addcontentsline{toc}{subsection}{Exercise 4}
\subsection*{Exercise 4}


\myFigure{../material_P3/protect_out4/asoc/p2/4096/lectura.png}{Cache read misses of the multiplication programs (varying associativity)}{asoc_lectura}{0.55}

\myFigure{../material_P3/protect_out4/asoc/p2/4096/escritura.png}{Cache write misses of the multiplication programs (varying associativity)}{asoc_escritura}{0.55}

\end{document}


\begin{lstlisting}[language=C, texcl=true]
    typedef struct Mine_struct_{
        long int target;
        long int begin; //índice por el que empieza a buscar el hilo
        long int end; //índice hasta el que el hilo busca (no incluido)
    } Mine_struct;  
\end{lstlisting}





